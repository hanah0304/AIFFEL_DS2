{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90df461d",
   "metadata": {},
   "source": [
    "# 의사결정 나무모델    \n",
    "\n",
    "- 지도학습 알고리즘 (분류, 회귀)\n",
    "- 직관적인 알고리즘 (이해 쉬움)\n",
    "- 과대적합되기 쉬운 알고리즘 (트리 깊이 제한 필요)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c59f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88193fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284, 30), (285, 30), (284,), (285,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 생성\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "def make_dataset():\n",
    "    iris = load_breast_cancer()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['target'] = iris.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df.drop('target', axis=1), df['target'], test_size=0.5, random_state=1004)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_dataset()\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7e9d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    190\n",
       "0     94\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 확인\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5e6be",
   "metadata": {},
   "source": [
    "# 2. 의사결정나무\n",
    "- 지도학습(분류)에서 가장 유용하게 사용되고 있는 기법 중 하나입니다.\n",
    "- 트리의 루트(root)에서 시작해서 정보이득이 최대가 되는 특성으로 데이터를 나눕니다.\n",
    "- 정보이득(information gain)이 최대가 되는 특성을 나누는 기준(불순도를 측정하는 기준)은 '지니'와 '엔트로피'가 사용됩니다.\n",
    "- 데이터가 한 종류만 있다면 엔트로피/지니 불순도는 0에 가깝고, 서로 다른 데이터의 비율이 비슷하면 1에 가깝습니다.\n",
    "- 정보이득(information gain)이 최대라는 것은 불순도를 최소화 하는 방향입니다. (1-불순도)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88040cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9263157894736842"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정나무\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90537d78",
   "metadata": {},
   "source": [
    "# 3. 의사결정나무 하이퍼파라미터\n",
    "- criterion (기본값 gini) : 불순도 지표 (또는 엔트로피 불순도 entropy)\n",
    "- max_depth (기본값 None) : 최대 한도 깊이\n",
    "- min_samples_split (기본값 2) : 자식 노드를 갖기 위한 최소한의 데이터 수\n",
    "- min_samples_leaf (기본값 1) : 리프 노드가 되기 위한 최소 샘플 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da35a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9403508771929825"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정나무 하이퍼파라미터\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion = 'entropy',\n",
    "    max_depth = 4,\n",
    "    min_samples_split = 2,\n",
    "    min_samples_leaf = 2,\n",
    "    random_state = 0)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f3a3c",
   "metadata": {},
   "source": [
    "# 랜덤포레스트\n",
    "\n",
    "- 여러개의 의사결정 트리로 구성\n",
    "- 앙상블 방법 중 배깅(bagging) 방식\n",
    "- 부트스트랩 샘플링 (데이터셋 중복 허용)\n",
    "- 최종 다수결 투표\n",
    "- 과대적합 가능성 낮음\n",
    "\n",
    "## 앙상블 방법\n",
    "\n",
    "-배깅: 같은 알고리즘으로 여러 모델을 만들어 분류함(랜덤포레스트)\n",
    "\n",
    "-부스팅: 학습과 예측을 하면서 가중치 반영 (xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8714ca11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9438596491228071"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 모델 선택\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1396c583",
   "metadata": {},
   "source": [
    "# 랜덤포레스트의 하이퍼파라미터\n",
    "- n_estimators (기본값 100) : 트리의 수\n",
    "- criterion (기본값 gini) : 불순도 지표\n",
    "- max_depth (기본값 None) : 최대 한도 깊이\n",
    "- min_samples_split (기본값 2) : 자식 노드를 갖기 위한 최소한의 데이터 수\n",
    "- min_samples_leaf (기본값 1) : 리프 노드가 되기 위한 최소 샘플 수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c50a968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 모델 선택\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a77349",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "- 트리 앙상블 중 성능이 좋은 알고리즘\n",
    "- eXtreme Gradient Boosting를 줄여서 XGBoost라고 한다.\n",
    "- 약한 학습기가 계속해서 업데이트를 하며 좋은 모델을 만들어 간다.\n",
    "- 부스팅(앙상블) 기반의 알고리즘\n",
    "- 캐글(글로벌 AI 경진대회)에서 뛰어난 성능을 보이면서 인기가 높아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec0bbb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9508771929824561"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)\n",
    "\n",
    "# use_label_encoder=False, eval_metric='logloss'는 오류 제거용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df23af6",
   "metadata": {},
   "source": [
    "# xgboost 하이퍼 파라미터\n",
    "\n",
    "- booster (기본값 gbtree) : 부스팅 알고리즘 (또는 dart, gblinear)\n",
    "- objective (기본값 binary:logistic) : 이진분류 (다중분류: multi:softmax)\n",
    "- max_depth (기본값 6) : 최대 한도 깊이\n",
    "- learning_rate (기본값 0.1) : 학습률\n",
    "- n_estimators (기본값 100) : 트리의 수\n",
    "- subsample (기본값 1) : 훈련 샘플 개수의 비율\n",
    "- colsample_bytree (기본값 1) : 특성 개수의 비율\n",
    "- n_jobs (기본값 1) : 사용 코어 수 (-1: 모든 코어를 다 사용)\n",
    "\n",
    "# *learning_rate와 n_estimators 값은 반대방향으로 같이 움직여줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "033a4da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost 하이퍼 파라미터\n",
    "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss',\n",
    "                     booster = 'gbtree',\n",
    "                     objective = 'binary:logistic',\n",
    "                     max_depth = 5,\n",
    "                     learning_rate = 0.1,\n",
    "                     n_estimators = 500,\n",
    "                     subsample = 1,\n",
    "                     colsample_bytree = 1,\n",
    "                     n_jobs = -1)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)\n",
    "\n",
    "\n",
    "# - booster (기본값 gbtree) : 부스팅 알고리즘 (또는 dart, gblinear)\n",
    "# - objective (기본값 binary:logistic) : 이진분류 (다중분류: multi:softmax)\n",
    "# - max_depth (기본값 6) : 최대 한도 깊이\n",
    "# - learning_rate (기본값 0.1) : 학습률\n",
    "# - n_estimators (기본값 100) : 트리의 수\n",
    "# - subsample (기본값 1) : 훈련 샘플 개수의 비율\n",
    "# - colsample_bytree (기본값 1) : 특성 개수의 비율\n",
    "# - n_jobs (기본값 1) : 사용 코어 수 (-1: 모든 코어를 다 사용)\n",
    "\n",
    "# 0.9614035087719298 (n_estimators = 100)\n",
    "# 0.9649122807017544 (n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "814739a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.61675\n",
      "[1]\tvalidation_0-logloss:0.55412\n",
      "[2]\tvalidation_0-logloss:0.50327\n",
      "[3]\tvalidation_0-logloss:0.46000\n",
      "[4]\tvalidation_0-logloss:0.42249\n",
      "[5]\tvalidation_0-logloss:0.39066\n",
      "[6]\tvalidation_0-logloss:0.36314\n",
      "[7]\tvalidation_0-logloss:0.33875\n",
      "[8]\tvalidation_0-logloss:0.31792\n",
      "[9]\tvalidation_0-logloss:0.29937\n",
      "[10]\tvalidation_0-logloss:0.28334\n",
      "[11]\tvalidation_0-logloss:0.26923\n",
      "[12]\tvalidation_0-logloss:0.25589\n",
      "[13]\tvalidation_0-logloss:0.24533\n",
      "[14]\tvalidation_0-logloss:0.23600\n",
      "[15]\tvalidation_0-logloss:0.22732\n",
      "[16]\tvalidation_0-logloss:0.22058\n",
      "[17]\tvalidation_0-logloss:0.21358\n",
      "[18]\tvalidation_0-logloss:0.20829\n",
      "[19]\tvalidation_0-logloss:0.20228\n",
      "[20]\tvalidation_0-logloss:0.19858\n",
      "[21]\tvalidation_0-logloss:0.19410\n",
      "[22]\tvalidation_0-logloss:0.19093\n",
      "[23]\tvalidation_0-logloss:0.18808\n",
      "[24]\tvalidation_0-logloss:0.18447\n",
      "[25]\tvalidation_0-logloss:0.18285\n",
      "[26]\tvalidation_0-logloss:0.18104\n",
      "[27]\tvalidation_0-logloss:0.17707\n",
      "[28]\tvalidation_0-logloss:0.17486\n",
      "[29]\tvalidation_0-logloss:0.17338\n",
      "[30]\tvalidation_0-logloss:0.17141\n",
      "[31]\tvalidation_0-logloss:0.17079\n",
      "[32]\tvalidation_0-logloss:0.16993\n",
      "[33]\tvalidation_0-logloss:0.16936\n",
      "[34]\tvalidation_0-logloss:0.16685\n",
      "[35]\tvalidation_0-logloss:0.16689\n",
      "[36]\tvalidation_0-logloss:0.16691\n",
      "[37]\tvalidation_0-logloss:0.16745\n",
      "[38]\tvalidation_0-logloss:0.16632\n",
      "[39]\tvalidation_0-logloss:0.16670\n",
      "[40]\tvalidation_0-logloss:0.16629\n",
      "[41]\tvalidation_0-logloss:0.16620\n",
      "[42]\tvalidation_0-logloss:0.16608\n",
      "[43]\tvalidation_0-logloss:0.16631\n",
      "[44]\tvalidation_0-logloss:0.16528\n",
      "[45]\tvalidation_0-logloss:0.16582\n",
      "[46]\tvalidation_0-logloss:0.16613\n",
      "[47]\tvalidation_0-logloss:0.16710\n",
      "[48]\tvalidation_0-logloss:0.16802\n",
      "[49]\tvalidation_0-logloss:0.16836\n",
      "[50]\tvalidation_0-logloss:0.16939\n",
      "[51]\tvalidation_0-logloss:0.16862\n",
      "[52]\tvalidation_0-logloss:0.16917\n",
      "[53]\tvalidation_0-logloss:0.16952\n",
      "[54]\tvalidation_0-logloss:0.17049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9543859649122807"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조기종료\n",
    "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss',\n",
    "                     learning_rate = 0.1,\n",
    "                     n_estimators = 500)\n",
    "\n",
    "# 검증할 데이터셋 추가\n",
    "eval_set = [(X_test, y_test)]\n",
    "model.fit(X_train, y_train, eval_set=eval_set, early_stopping_rounds=10) # 학습 검증할 데이터셋 추가, 성능 개선 없을 경우 조기 종료\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed540732",
   "metadata": {},
   "source": [
    "# 교차검증\n",
    "- 일반적으로 모델을 학습시킬 때 데이터를 train set과 test set으로 나누어 train set을 가지고 학습을 수행합니다.\n",
    "- 교차검증이란 여기서 train set을 다시 train set과 validation set으로 나누어 학습 중 검증과 수정을 수행하는 것을 의미합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82bb0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "def make_dataset2():\n",
    "    iris = load_breast_cancer()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['target'] = iris.target\n",
    "    return df.drop('target', axis=1), df['target']\n",
    "X, y = make_dataset2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e9401a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8771929824561403\n",
      "0.9122807017543859\n",
      "0.9473684210526315\n",
      "0.9385964912280702\n",
      "0.8407079646017699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd6d8d",
   "metadata": {},
   "source": [
    "# Stratified Kfold\n",
    "- 불균형한 타겟 비율을 가진 데이터가 한쪽으로 치우치는 것을 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2e4e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9035087719298246\n",
      "0.9210526315789473\n",
      "0.9122807017543859\n",
      "0.9473684210526315\n",
      "0.9026548672566371\n"
     ]
    }
   ],
   "source": [
    "# Stratified Kfold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "for train_idx, test_idx in kfold.split(X,y): # y값까지 추가해줘야함!\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa96343",
   "metadata": {},
   "source": [
    "# 사이킷런 교차검증\n",
    "- 사이킷런 내부 API를 통해 FIT(학습) - PREDICT(예측) - EVALUATION(평가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29b346bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88947368, 0.94210526, 0.86243386])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차검증\n",
    "# API 불러오기\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, cv=3) # cv뒤 숫자를 바꿔주면 몇개로 데이터를 쪼갤 것인지 다양한 검증 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72a2d1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8980042699340944"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_val_score의 평균 점수 확인\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X, y, cv=3)  # 해당 함수를 scores로 저장\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1f0b89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90350877, 0.92105263, 0.9122807 , 0.94736842, 0.90265487])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차검증 StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "scores = cross_val_score(model, X, y, cv=kfold)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75c05436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9173730787144851"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e18643e",
   "metadata": {},
   "source": [
    "# 평가(분류)\n",
    "- 정확도 accuracy: 실제 값과 예측값이 일치하는 비율\n",
    "- 정밀도 precision: 양성이라고 예측한 값 중 실제 양성인 값의 비율 (암이라고 예측 한 값 중 실제 암)\n",
    "- 재현율 recall: 실제 양성 값 중 양성으로 예측한 값의 비율 (암을 암이라고 판단)\n",
    "- F1: 정밀도와 재현율의 조화평균\n",
    "- ROC-AUC\n",
    "- ROC: 참 양성 비율(True Positive Rate)에 대한 거짓 양성 비율(False Positive Rate) 곡선\n",
    "- AUC: ROC곡선 면적 아래 (완벽하게 분류되면 AUC가 1임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "840c69ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9026548672566371"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7675fee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정밀도\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7f8a116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873239436619719"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 재현율\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "307d0bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9197080291970803"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cb9e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999664654594232"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc_auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict_proba(X_test) # predict가 아니라 predict_proba(0,1이 아니라 확률로 받음)\n",
    "roc_auc_score(y_test, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de376d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: graphviz\n",
      "Successfully installed graphviz-0.20.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739fa16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
